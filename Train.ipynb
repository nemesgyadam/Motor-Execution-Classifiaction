{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import keras_tuner as kt\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers as layers\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D, Activation, Dense, Conv1D, Conv2D, Dropout, Flatten, MaxPooling2D, BatchNormalization, GlobalMaxPooling1D\n",
    "from tensorflow.keras import optimizers\n",
    "import itertools\n",
    "from sklearn.utils import shuffle\n",
    "from scipy import signal\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras import regularizers\n",
    "from EEGModels import EEGNet    \n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold, KFold\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showHistory(history):\n",
    "    plt.rcParams['figure.figsize'] = [5, 5]\n",
    "    for key in history.history.keys():\n",
    "\n",
    "        if 'val_' not in key and 'lr' != key:\n",
    "            try:\n",
    "                plt.clf()\n",
    "                plt.plot(history.history[key])\n",
    "                plt.plot(history.history['val_'+key])\n",
    "                plt.ylabel(key)\n",
    "                plt.xlabel('epoch')\n",
    "                plt.legend(['train', 'validation'], loc='upper left')\n",
    "                plt.show()\n",
    "            except:\n",
    "                ...\n",
    "\n",
    "classes = []\n",
    "def smoothLabels(label, factor = 0.):\n",
    "    label *= (1 - factor)\n",
    "    label += (factor / len(label))\n",
    "    return label\n",
    "\n",
    "def oneHot(label, classes = classes):\n",
    "    label = to_categorical(label,num_classes=len(classes))\n",
    "    return smoothLabels(label)\n",
    "\n",
    "def applyOneHot(data):\n",
    "    new = []\n",
    "    for y in data:\n",
    "        new.append(oneHot(y))\n",
    "    return np.array(new)\n",
    "\n",
    "def DCFilter(data):\n",
    "    new_data = []\n",
    "    for d in data:\n",
    "        new_data.append(d-np.mean(d))\n",
    "    return np.array(new_data)\n",
    "\n",
    "def notchFilter(data, f0 = 60.0, Q = 30.0, fs = 500):\n",
    "    b, a = signal.iirnotch(f0, Q, fs)\n",
    "    data = signal.filtfilt(b, a, data, axis=1)\n",
    "    return np.array(data)\n",
    "\n",
    "def preProcess(data):\n",
    "    data = signal.resample(data,   signal_length,axis =-1)\n",
    "  \n",
    "    new_data = []\n",
    "    for d in data:\n",
    "        d = DCFilter(d)\n",
    "        d = notchFilter(d)\n",
    "        scaler = StandardScaler()\n",
    "        scaler.fit(d)\n",
    "        d = scaler.transform(d)\n",
    "        new_data.append(normalize(d, norm='l2'))\n",
    "    return np.array(new_data)\n",
    "\n",
    "def showMe(data):\n",
    "    \n",
    "    plt.rcParams[\"figure.figsize\"] = [17, 2]\n",
    "    fig, (c1, c2, c3, c4, c5, c6) = plt.subplots(1, 6)\n",
    "    c1.plot(data[0])\n",
    "    c2.plot(data[1])\n",
    "    c3.plot(data[2])\n",
    "    c4.plot(data[3])\n",
    "    c5.plot(data[4])\n",
    "    c6.plot(data[5])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 6, 100)\n"
     ]
    }
   ],
   "source": [
    "signal_length = 100\n",
    "classes = ['Rest','Left','Right']\n",
    "resource_path = 'resources/'\n",
    "train_sessions = ['session_0', 'session_1', 'session_2']\n",
    "\n",
    "class_0 = []\n",
    "class_1 = []\n",
    "class_2 = []\n",
    "for session in train_sessions:\n",
    "    class_0.append(np.load(os.path.join(resource_path,session,classes[0]+'.npy')))\n",
    "    class_1.append(np.load(os.path.join(resource_path,session,classes[1]+'.npy')))\n",
    "    class_2.append(np.load(os.path.join(resource_path,session,classes[2]+'.npy')))\n",
    "class_0 = np.concatenate((class_0),axis=0)\n",
    "class_1 = np.concatenate((class_1),axis=0)\n",
    "class_2 = np.concatenate((class_2),axis=0)\n",
    "\n",
    "\n",
    "class_0 = preProcess(class_0)\n",
    "class_1 = preProcess(class_1)\n",
    "class_2 = preProcess(class_2)\n",
    "print(class_0.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_0_avg = class_0.mean(axis=0)\n",
    "showMe(class_0_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_1_avg = class_1.mean(axis=0)\n",
    "showMe(class_1_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_2_avg = class_2.mean(axis=0)\n",
    "showMe(class_2_avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    showMe(class_1[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "    showMe(class_0[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180, 6, 100, 1)\n",
      "(180,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lapos\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\ipykernel_launcher.py:31: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    }
   ],
   "source": [
    "X = np.concatenate((class_0,class_1,class_2),axis = 0)\n",
    "y = np.concatenate(( np.zeros(class_0.shape[0]),np.ones(class_1.shape[0]),np.ones(class_1.shape[0])*2))\n",
    "\n",
    "\n",
    "#SHUFFLE DATA\n",
    "c = list(zip(X, y))\n",
    "random.shuffle(c)\n",
    "X,y = zip(*c)\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "X = np.expand_dims(X, axis = -1) \n",
    "\n",
    "y = applyOneHot(y)\n",
    "\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(360, 6, 100, 1)\n",
      "(360,)\n"
     ]
    }
   ],
   "source": [
    "#AUGMENT\n",
    "noise = np.random.normal(0,0.1,X.size)\n",
    "noise = np.reshape(noise,X.shape)\n",
    "\n",
    "augmented = X + noise\n",
    "X_aug = np.concatenate((X,augmented))\n",
    "y_aug = np.concatenate((y,y))\n",
    "\n",
    "print(X_aug.shape)\n",
    "print(y_aug.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    inspected_chanels= X.shape[1]\n",
    "    signal_length=     X.shape[2]\n",
    "    input_layer = keras.Input(shape = (inspected_chanels,signal_length,1), name='input')\n",
    "    x     = layers.Conv2D(64, kernel_size=(1,5), padding='same', activation='relu')(input_layer)\n",
    "    x     = layers.BatchNormalization()(x)\n",
    "    x     = layers.AveragePooling2D(pool_size=(1,5))(x)\n",
    "\n",
    "    x     = layers.Conv2D(32, kernel_size=(2,1), padding='same', activation='relu')(x)\n",
    "    x     = layers.BatchNormalization()(x)\n",
    "    x     = layers.AveragePooling2D(pool_size=(2,1))(x)\n",
    "\n",
    "    x     = layers.Conv2D(16, 16, padding='same', activation='relu')(x)\n",
    "    x     = layers.BatchNormalization()(x)\n",
    "\n",
    "    x     = layers.GlobalAveragePooling2D()(x)\n",
    "    x     = layers.Dense(64)(x)\n",
    "    x     = layers.Dropout(0.2)(x)\n",
    "    output = layers.Dense(len(classes), activation='softmax')(x)\n",
    "\n",
    "    model = keras.Model(inputs=input_layer, outputs=output)\n",
    "\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#model = get_model()\n",
    "model=EEGNet(nb_classes=3,\n",
    "                Chans=6,\n",
    "                Samples = signal_length,  # sure?\n",
    "                kernLength = 20,\n",
    ")\n",
    "lr_schedule = keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=1e-2,\n",
    "    decay_steps=500,\n",
    "    decay_rate=0.9\n",
    "    )\n",
    "\n",
    "opt = keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.9, nesterov=True)\n",
    "model.compile(optimizer=opt,\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy']\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=10)\n",
    "tf.config.run_functions_eagerly(True)\n",
    "accs = []\n",
    "models = []\n",
    "for train, test in skf.split(X_aug, y_aug.argmax(axis=1)):\n",
    "  \n",
    "    X_train = X_aug[train]\n",
    "    X_test  = X_aug[test]\n",
    "    y_train = y_aug[train]\n",
    "    y_test  = y_aug[test]\n",
    "    print(X_train.shape, y_train.shape)\n",
    "\n",
    "   \n",
    "\n",
    "    batch_size = 16 #len(X_train)\n",
    "    print(\"Batch size: {}\".format(batch_size))\n",
    "\n",
    "    history = model.fit(X_train,\n",
    "                        y_train,\n",
    "                        validation_data=(X_test, y_test),\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=100,\n",
    "                        shuffle=True)\n",
    "\n",
    "    showHistory(history)          \n",
    "    acc = max(history.history['val_accuracy'])\n",
    "    accs.append(acc)                       \n",
    "    models.append(model)\n",
    "\n",
    "\n",
    "    if acc > 0.9:\n",
    "        break\n",
    "\n",
    "\n",
    "model = models[accs.index(max(accs))]\n",
    "for acc in accs:\n",
    "    print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: val_loss_083\\assets\n"
     ]
    }
   ],
   "source": [
    "model.save('val_loss_083')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[47.,  5.,  8.],\n",
       "       [ 4., 44., 12.],\n",
       "       [ 6., 21., 33.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model(X)\n",
    "conf_matrix = np.zeros((3,3))\n",
    "for i in range(int(len(pred))):\n",
    "    prediction = np.argmax(pred[i])\n",
    "    gt         = np.argmax(y[i])\n",
    "    conf_matrix[gt][prediction] += 1\n",
    "conf_matrix"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a81b55685ebb6380129efe90592a7e4f2f571da2ab32c8bbcf8b970d830ead19"
  },
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
